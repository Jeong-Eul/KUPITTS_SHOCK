{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents = pd.read_csv('./chartevents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_status = chartevents[chartevents['itemid']==223758]\n",
    "chartevents = 0\n",
    "code_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmo = code_status[code_status['value']=='Comfort measures only']\n",
    "cmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmo_output = cmo[['stay_id','value']]\n",
    "cmo_output.rename(columns={'value':'CMO'}, inplace=True)\n",
    "cmo_output = cmo_output.drop_duplicates(subset=['stay_id'])\n",
    "cmo_output.reset_index(drop=True, inplace=True)\n",
    "cmo_output['CMO'] = 1\n",
    "cmo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmo_output2 = cmo[['stay_id','charttime']]\n",
    "cmo_output2 = cmo_output2.drop_duplicates(subset=['stay_id'])\n",
    "cmo_output2.reset_index(drop=True, inplace=True)\n",
    "cmo_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_data = pd.read_csv('./1hr Shock Research ambiguous Dataset_type27.csv')\n",
    "non_ambiguous_data = pd.read_csv('./1hr Shock Research non_ambiguous Dataset_type27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ambiguous_data.shape)\n",
    "print(non_ambiguous_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_data = pd.merge(ambiguous_data, cmo_output, on=['stay_id'], how='left')\n",
    "non_ambiguous_data = pd.merge(non_ambiguous_data, cmo_output, on=['stay_id'], how='left')\n",
    "\n",
    "#ambiguous_data.fillna(0, inplace=True)\n",
    "#non_ambiguous_data.fillna(0, inplace=True)\n",
    "\n",
    "print(ambiguous_data.shape)\n",
    "print(non_ambiguous_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_data['time'] = pd.to_datetime(ambiguous_data['time'])\n",
    "non_ambiguous_data['time'] = pd.to_datetime(non_ambiguous_data['time'])\n",
    "cmo_output2['charttime'] = pd.to_datetime(cmo_output2['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_active_after_cmo(x):\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if x['CMO'].max() > 0:\n",
    "        cmo_charttime_series = cmo_output2[cmo_output2['stay_id']==x['stay_id'][0]]['charttime'].max()\n",
    "        \n",
    "        #cmo charttime 이전의 데이터 찾기\n",
    "        before_cmo_data = x[x['time']<=cmo_charttime_series]\n",
    "\n",
    "        return before_cmo_data\n",
    "    else :\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_cmo_data_ambiguous = ambiguous_data.groupby('stay_id').apply(cut_active_after_cmo)\n",
    "before_cmo_data_non_ambiguous = non_ambiguous_data.groupby('stay_id').apply(cut_active_after_cmo)\n",
    "\n",
    "before_cmo_data_ambiguous.reset_index(drop=True, inplace=True)\n",
    "before_cmo_data_non_ambiguous.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('ambiguous_data', len(ambiguous_data))\n",
    "print('before_cmo_data_ambiguous', len(before_cmo_data_ambiguous))\n",
    "\n",
    "print('non_ambiguous_data', len(non_ambiguous_data))\n",
    "print('before_cmo_data_non_ambiguous', len(before_cmo_data_non_ambiguous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = before_cmo_data_ambiguous['stay_id'].unique().tolist()\n",
    "b = before_cmo_data_non_ambiguous['stay_id'].unique().tolist()\n",
    "\n",
    "all_ambiguous_patient = list(set(a) - set(b))\n",
    "\n",
    "print(len(all_ambiguous_patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_cmo_data_ambiguous.to_csv('./1hr Shock Research ambiguous Dataset_type27_cmo.csv', index=False)\n",
    "before_cmo_data_non_ambiguous.to_csv('./1hr Shock Research non_ambiguous Dataset_type27_cmo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat ambiguous and non ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_data = pd.read_csv('./1hr Shock Research ambiguous Dataset_type27_cmo.csv')\n",
    "non_ambiguous_data = pd.read_csv('./1hr Shock Research non_ambiguous Dataset_type27_cmo.csv')\n",
    "\n",
    "output = pd.concat([ambiguous_data, non_ambiguous_data], axis=0, ignore_index=True)\n",
    "output = output.sort_values(by=['stay_id', 'time'], ascending=[True,True])\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def delete_no_vaso_patients(x):\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if len(x[x['Vasopressors']>0]) > 0:\n",
    "        return x\n",
    "    \n",
    "data_delete_no_vaso_patients = output.groupby('stay_id').apply(delete_no_vaso_patients)\n",
    "data_delete_no_vaso_patients.reset_index(drop=True, inplace=True)\n",
    "data_delete_no_vaso_patients['stay_id'].unique().shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bye_bye(x): \n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    column_list = ['Blood pressure systolic', 'Blood pressure diastolic', 'Blood pressure mean']\n",
    "    \n",
    "    has_nan = x[column_list].isna().any(axis=1).any()\n",
    "\n",
    "    if has_nan == False:\n",
    "        return x\n",
    "    \n",
    "    else :\n",
    "        df_notna = x.dropna(subset=column_list)\n",
    "        df_notna.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_isna = x[x[column_list].isnull().any(axis=1)]\n",
    "\n",
    "        if len(df_notna)!=0:\n",
    "            if df_notna['Actual Troponin test'][0]==0:\n",
    "                df_notna['Actual Troponin test'][0] = df_isna['Actual Troponin test'].max()\n",
    "\n",
    "            if df_notna['Actual Creatinine test'][0]==0: \n",
    "                df_notna['Actual Creatinine test'][0] = df_isna['Actual Creatinine test'].max()\n",
    "\n",
    "            if df_notna['Actual Lactate test'][0]==0:\n",
    "                df_notna['Actual Lactate test'][0] = df_isna['Actual Lactate test'].max()\n",
    "\n",
    "            return df_notna\n",
    "\n",
    "cleansed_data = data_delete_no_vaso_patients.groupby('stay_id').apply(Bye_bye)\n",
    "print(cleansed_data.shape)\n",
    "#imputated_data = 0\n",
    "cleansed_data.reset_index(drop=True, inplace=True)\n",
    "print(cleansed_data['stay_id'].unique().shape)\n",
    "\n",
    "cleansed_data.to_csv('./1hr Shock Research type27 for Cont.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    feature_ls = ['Heart rate', 'Blood pressure systolic', 'Blood pressure diastolic',\n",
    "                  'Blood pressure mean', 'Respiratory rate', 'SpO2', 'Temperature', 'Shock index']\n",
    "\n",
    "    len_traj = len(df)\n",
    "    def rsi(series, period):\n",
    "        delta = series.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "        loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=period, min_periods=1).mean()\n",
    "        avg_loss = loss.rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs + 0.00000001))\n",
    "        return rsi\n",
    "\n",
    "    rsi_df = df.copy()\n",
    "    for column in feature_ls:\n",
    "        rsi_df[f'{column}_RSI'] = rsi(df[column], len_traj)\n",
    "        rsi_df[f'{column}_RSI'].fillna(0, inplace=True)\n",
    "    \n",
    "    return rsi_df\n",
    "\n",
    "cleansed_data_rsi = cleansed_data.groupby('stay_id').apply(calculate_rsi)\n",
    "cleansed_data_rsi.reset_index(drop=True, inplace=True)\n",
    "cleansed_data_rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_feature(x):\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    vital_ls = ['Heart rate', 'Blood pressure systolic', 'Blood pressure diastolic',\n",
    "                  'Blood pressure mean', 'Respiratory rate', 'SpO2', 'Temperature', 'Shock index']\n",
    "\n",
    "    for vital_feature in vital_ls:\n",
    "        x[f'{vital_feature}_delta'] = None\n",
    "        x[f'{vital_feature}_delta_ratio'] = None\n",
    "\n",
    "        first_Not_none_index = None  # 변수 선언 및 초기화\n",
    "        for p in range(len(x)):\n",
    "            if not pd.isna(x[vital_feature][p]):\n",
    "                first_Not_none_index = p  # 변수 할당\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if first_Not_none_index is not None:\n",
    "            x[f'{vital_feature}_delta'][first_Not_none_index] = 0\n",
    "            x[f'{vital_feature}_delta_ratio'][first_Not_none_index] = 0\n",
    "            for index in range(first_Not_none_index+1, len(x)):\n",
    "                x[f'{vital_feature}_delta'][index] = x[f'{vital_feature}'][index] - x[f'{vital_feature}'][index-1]\n",
    "                x[f'{vital_feature}_delta_ratio'][index] = (x[f'{vital_feature}'][index] - x[f'{vital_feature}'][index-1])/(x[f'{vital_feature}'][index-1]+0.000001)\n",
    "\n",
    "    return x\n",
    "\n",
    "cleansed_data_delta = cleansed_data_rsi.groupby('stay_id').apply(delta_feature)\n",
    "cleansed_data_delta.reset_index(drop=True, inplace=True)\n",
    "cleansed_data_delta.to_csv('./1hr Shock Research type27 for Cont_delta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data_delta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data_delta.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleansed_data_delta = pd.read_csv('./1hr Shock Research type27 for Cont_delta.csv')\n",
    "cleansed_data_delta['Binary Shock'] = 0\n",
    "cleansed_data_delta['Binary Shock'][cleansed_data_delta[(cleansed_data_delta['Shock']>0)].index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shock_gap_df(x):\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    shock_index_ls = []\n",
    "\n",
    "    for shock_index in range(len(x)):\n",
    "        if x['Shock'][shock_index] > 0:\n",
    "            shock_index_ls.append(shock_index)\n",
    "\n",
    "    if len(shock_index_ls) < 2:\n",
    "        return x\n",
    "    \n",
    "    elif len(shock_index_ls) > 1 :\n",
    "        df = x.loc[shock_index_ls[0]+1 : shock_index_ls[-1]-1]\n",
    "        x['Binary Shock'][df.index] = 1\n",
    "\n",
    "        # 조건을 만족하는 인덱스를 찾음\n",
    "        condition = df[(df['Blood pressure mean'] >= 75) & (df['Vasopressors'] == 0) & (df['LR_NS'] == 0) & (df['Shock'] == 0)]\n",
    "        \n",
    "        if len(condition) > 5 :\n",
    "            condition_indices = condition.index\n",
    "            # 연속적으로 6시간 이상 유지하는 경우를 찾음\n",
    "            continuous_blocks = []\n",
    "            current_block = []\n",
    "\n",
    "            for idx in condition_indices:\n",
    "                if (len(current_block) == 0) :\n",
    "                    current_block.append(idx)\n",
    "                elif (len(current_block)>0) & (idx == current_block[-1] + 1):\n",
    "                    current_block.append(idx)\n",
    "                else:\n",
    "                    continuous_blocks.append(current_block)\n",
    "                    current_block = [idx]\n",
    "            \n",
    "            if len(current_block) > 0:\n",
    "                continuous_blocks.append(current_block)\n",
    "\n",
    "            # 6시간 이상 연속된 블록을 찾아서 처리\n",
    "            for block in continuous_blocks:\n",
    "                if len(block) >= 6:\n",
    "                    x.loc[block, 'Binary Shock'] = 0\n",
    "                    print(x['stay_id'][0])\n",
    "        \n",
    "            return x\n",
    "        else :\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_complete_gap = cleansed_data_delta.groupby('stay_id').apply(get_shock_gap_df)\n",
    "output_complete_gap.reset_index(drop=True, inplace=True)\n",
    "output_complete_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleansed_data_delta['Binary Shock'].value_counts()/len(cleansed_data_delta))\n",
    "\n",
    "print(output_complete_gap['Binary Shock'].value_counts()/len(output_complete_gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleansed_data_delta.shape)\n",
    "print(output_complete_gap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(output_complete_gap.stay_id.unique().shape)\n",
    "Lactate_abn_stay_id_ls = output_complete_gap[output_complete_gap['Lactate']>10000].stay_id.unique().tolist()\n",
    "\n",
    "output_complete_gap = output_complete_gap[~output_complete_gap['stay_id'].isin(Lactate_abn_stay_id_ls)]\n",
    "print(output_complete_gap.stay_id.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_complete_gap[output_complete_gap['LR_NS']==0])/len(output_complete_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_complete_gap.to_csv('./1hr Shock Research type27 for Cont_delta preprocessed GAP Mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_complete_gap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KUxPITTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
